{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Example 3: Gradio Example"
      ],
      "metadata": {
        "id": "NJv5H7z7oU2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio # remove '-q' to see the output"
      ],
      "metadata": {
        "id": "lUGyLa49oT7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "uMXmldE0Gr-T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data and split into data and labels\n",
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()\n",
        "# We use only The 0'th and 1'st columns.\n",
        "# These correspond to sepal length and width.\n",
        "X = iris_dataset['data'][:, [0, 1]]\n",
        "y = iris_dataset['target']\n",
        "\n",
        "# Split into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Import and train a machine learning model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1ntB5MuGzk4",
        "outputId": "cf6bc8b5-1910-47d9-bb90-9d80486c1aa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7894736842105263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_flower(sepal_length, sepal_width):\n",
        "    \"\"\"\n",
        "    Predicts whether an Iris flower is a Versicolor, Virginica, or Setosa.\n",
        "\n",
        "    Args:\n",
        "        sepal_length (float): The flower's average sepal length in cm.\n",
        "        sepal_width (float): The flower's average sepal width in cm.\n",
        "\n",
        "    Returns:\n",
        "        str: \"Virginica\", \"Setosa\", or \"Versicolor\".\n",
        "    \"\"\"\n",
        "\n",
        "    # Reshape the input data for prediction\n",
        "    input_data = np.array([sepal_length, sepal_width]).reshape(1, -1)\n",
        "\n",
        "    # Get the prediction\n",
        "    prediction = rf.predict(input_data)\n",
        "\n",
        "    # Return the result\n",
        "    if prediction[0] == 0:\n",
        "        return \"Setosa\"\n",
        "    elif prediction[0] == 1:\n",
        "        return \"Versicolor\"\n",
        "    elif prediction[0] == 2:\n",
        "        return \"Virginica\"\n",
        "    else:\n",
        "        raise Exception\n",
        "\n"
      ],
      "metadata": {
        "id": "nwAXKwC8G4UJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 4:-gradio example to work in streamlit"
      ],
      "metadata": {
        "id": "GYp_7lsu9tz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBf5Z2Lh9GUo",
        "outputId": "fa35a574-66f6-4368-a9c7-09ebde993443"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import streamlit as st\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load the dataset and select features\n",
        "iris_dataset = load_iris()\n",
        "X = iris_dataset['data'][:, [0, 1]]  # Using sepal length and width only\n",
        "y = iris_dataset['target']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_flower(sepal_length, sepal_width):\n",
        "    input_data = np.array([sepal_length, sepal_width]).reshape(1, -1)\n",
        "    prediction = rf.predict(input_data)\n",
        "    return [\"Setosa\", \"Versicolor\", \"Virginica\"][prediction[0]]\n",
        "\n",
        "# Set up the Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_flower,\n",
        "    inputs=[\n",
        "        gr.Slider(minimum=X_train[:,0].min(), maximum=X_train[:,0].max(), value=X_train[:,0].mean(), label=\"Sepal length\"),\n",
        "        gr.Slider(minimum=X_train[:,1].min(), maximum=X_train[:,1].max(), value=X_train[:,1].mean(), label=\"Sepal width\"),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),\n",
        "    title=\"Flower Predictor\",\n",
        "    description=\"Enter Sepal Length and Sepal Width to predict the flower class.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio and get the URL\n",
        "_, gradio_url = iface.launch(share=True, debug=True)\n",
        "\n",
        "# Streamlit code to embed the Gradio app via iframe\n",
        "st.title(\"Flower Predictor with Gradio Embedded in Streamlit\")\n",
        "st.markdown(\"This is a Gradio interface embedded within a Streamlit app.\")\n",
        "st.components.v1.iframe(gradio_url, height=600, scrolling=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "fNYjQgIm-Gpi",
        "outputId": "ab1f713e-b0c4-4399-f505-c168585b33af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://786164bba46bfda0c2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://786164bba46bfda0c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://786164bba46bfda0c2.gradio.live\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2bb6c7404475>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Launch Gradio and get the URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradio_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Streamlit code to embed the Gradio app via iframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    }
  ]
}